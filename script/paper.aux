\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{plain}
\citation{johnson2016perceptual}
\citation{CycleGAN2017}
\citation{chen2018cartoongan}
\citation{chen2018cartoongan}
\babel@aux{american}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}\hskip -1em.~Introduction}{1}{section.1}\protected@file@percent }
\@writefile{brf}{\backcite{johnson2016perceptual, CycleGAN2017, chen2018cartoongan}{{1}{1}{figure.1}}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A simple illustration of our method. Images are decomposed into three cartoon representations, which guide the network optimization to generate cartoonized real-world photos.}}{1}{figure.1}\protected@file@percent }
\newlabel{fig:shinjuku}{{1}{1}{A simple illustration of our method. Images are decomposed into three cartoon representations, which guide the network optimization to generate cartoonized real-world photos}{figure.1}{}}
\@writefile{brf}{\backcite{chen2018cartoongan}{{1}{1}{figure.1}}}
\citation{tomasi1998bilateral}
\citation{he2010guided}
\citation{farbman2008edge}
\citation{min2014fast}
\citation{bi20151}
\citation{tomasi1998bilateral}
\citation{he2010guided}
\citation{farbman2008edge}
\citation{min2014fast}
\citation{bi20151}
\citation{xu2015deep}
\citation{fan2017generic}
\citation{fan2018image}
\citation{wu2018fast}
\citation{felzenszwalb2004efficient}
\citation{mori2005guiding}
\citation{moore2008superpixel}
\citation{achanta2012slic}
\citation{levinshtein2009turbopixels}
\citation{felzenszwalb2004efficient}
\citation{mori2005guiding}
\citation{moore2008superpixel}
\citation{comaniciu2002mean}
\citation{vedaldi2008quick}
\citation{achanta2012slic}
\citation{levinshtein2009turbopixels}
\citation{felzenszwalb2004efficient}
\citation{xu2011image}
\citation{lu2012combining}
\citation{gatys2015neural}
\citation{johnson2016perceptual}
\citation{van2004real}
\citation{curtis1997computer}
\citation{shahcheraghi2013effects}
\citation{chen2018cartoongan}
\citation{chen2018cartoongan}
\citation{wang2004video}
\citation{rosin2015non}
\citation{yang2010semantics}
\citation{gatys2015neural}
\citation{johnson2016perceptual}
\citation{dumoulin2016learned}
\citation{huang2017arbitrary}
\citation{li2017universal}
\citation{gatys2015neural}
\citation{johnson2016perceptual}
\citation{dumoulin2016learned}
\citation{huang2017arbitrary}
\citation{li2017universal}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Cartoon images with some typical and common features: 1. Global structures are composed of sparse color blocks and clear boundaries; 2. Details are outlines by sharp and clear contours; 3. Surfaces are flat and smooth.}}{2}{figure.2}\protected@file@percent }
\newlabel{fig:representation}{{2}{2}{Cartoon images with some typical and common features: 1. Global structures are composed of sparse color blocks and clear boundaries; 2. Details are outlines by sharp and clear contours; 3. Surfaces are flat and smooth}{figure.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}\hskip -1em.~Related Work}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}\hskip -1em.~Image Smoothing and Surface Extraction}{2}{subsection.2.1}\protected@file@percent }
\@writefile{brf}{\backcite{tomasi1998bilateral, he2010guided, farbman2008edge, min2014fast, bi20151}{{2}{2.1}{subsection.2.1}}}
\@writefile{brf}{\backcite{tomasi1998bilateral, he2010guided}{{2}{2.1}{subsection.2.1}}}
\@writefile{brf}{\backcite{farbman2008edge}{{2}{2.1}{subsection.2.1}}}
\@writefile{brf}{\backcite{min2014fast}{{2}{2.1}{subsection.2.1}}}
\@writefile{brf}{\backcite{bi20151}{{2}{2.1}{subsection.2.1}}}
\@writefile{brf}{\backcite{xu2015deep, fan2017generic, fan2018image}{{2}{2.1}{subsection.2.1}}}
\@writefile{brf}{\backcite{wu2018fast}{{2}{2.1}{subsection.2.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}\hskip -1em.~Superpixel and structure Extraction}{2}{subsection.2.2}\protected@file@percent }
\@writefile{brf}{\backcite{felzenszwalb2004efficient, mori2005guiding, moore2008superpixel, achanta2012slic, levinshtein2009turbopixels}{{2}{2.2}{subsection.2.2}}}
\@writefile{brf}{\backcite{felzenszwalb2004efficient, mori2005guiding, moore2008superpixel}{{2}{2.2}{subsection.2.2}}}
\@writefile{brf}{\backcite{comaniciu2002mean, vedaldi2008quick, achanta2012slic, levinshtein2009turbopixels}{{2}{2.2}{subsection.2.2}}}
\@writefile{brf}{\backcite{felzenszwalb2004efficient}{{2}{2.2}{subsection.2.2}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}\hskip -1em.~Non-photorealistic Rendering and Neural Style Transfer}{2}{subsection.2.3}\protected@file@percent }
\@writefile{brf}{\backcite{xu2011image, lu2012combining}{{2}{2.3}{subsection.2.3}}}
\@writefile{brf}{\backcite{gatys2015neural, johnson2016perceptual}{{2}{2.3}{subsection.2.3}}}
\@writefile{brf}{\backcite{van2004real, curtis1997computer}{{2}{2.3}{subsection.2.3}}}
\@writefile{brf}{\backcite{shahcheraghi2013effects}{{2}{2.3}{subsection.2.3}}}
\@writefile{brf}{\backcite{chen2018cartoongan}{{2}{2.3}{subsection.2.3}}}
\@writefile{brf}{\backcite{chen2018cartoongan}{{2}{2.3}{subsection.2.3}}}
\@writefile{brf}{\backcite{wang2004video}{{2}{2.3}{subsection.2.3}}}
\@writefile{brf}{\backcite{rosin2015non, yang2010semantics}{{2}{2.3}{subsection.2.3}}}
\@writefile{brf}{\backcite{gatys2015neural, johnson2016perceptual, dumoulin2016learned, huang2017arbitrary, li2017universal}{{2}{2.3}{subsection.2.3}}}
\@writefile{brf}{\backcite{gatys2015neural}{{2}{2.3}{subsection.2.3}}}
\@writefile{brf}{\backcite{johnson2016perceptual}{{2}{2.3}{subsection.2.3}}}
\citation{goodfellow2014generative}
\citation{pathak2016context}
\citation{sanakoyeu2018style}
\citation{chen2018cartoongan}
\citation{zhang2018two}
\citation{isola2017image}
\citation{huang2018multimodal}
\citation{lee2018diverse}
\citation{CycleGAN2017}
\citation{ignatov2018wespe}
\citation{johnson2016perceptual}
\citation{sanakoyeu2018style}
\citation{chen2018cartoongan}
\citation{li2019im2pencil}
\citation{zhang2016colorful}
\citation{zhang2018two}
\citation{CycleGAN2017}
\citation{simonyan2014very}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Our proposed image cartoonization system}}{3}{figure.3}\protected@file@percent }
\newlabel{fig:framework}{{3}{3}{Our proposed image cartoonization system}{figure.3}{}}
\@writefile{brf}{\backcite{dumoulin2016learned, huang2017arbitrary, li2017universal}{{3}{2.3}{subsection.2.3}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}\hskip -1em.~Generative Adversarial Networks}{3}{subsection.2.4}\protected@file@percent }
\@writefile{brf}{\backcite{goodfellow2014generative}{{3}{2.4}{subsection.2.4}}}
\@writefile{brf}{\backcite{pathak2016context}{{3}{2.4}{subsection.2.4}}}
\@writefile{brf}{\backcite{sanakoyeu2018style}{{3}{2.4}{subsection.2.4}}}
\@writefile{brf}{\backcite{chen2018cartoongan}{{3}{2.4}{subsection.2.4}}}
\@writefile{brf}{\backcite{zhang2018two}{{3}{2.4}{subsection.2.4}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}\hskip -1em.~Image-to-Image Translation}{3}{subsection.2.5}\protected@file@percent }
\@writefile{brf}{\backcite{isola2017image, huang2018multimodal, lee2018diverse, CycleGAN2017}{{3}{2.5}{subsection.2.5}}}
\@writefile{brf}{\backcite{ignatov2018wespe}{{3}{2.5}{subsection.2.5}}}
\@writefile{brf}{\backcite{johnson2016perceptual, sanakoyeu2018style}{{3}{2.5}{subsection.2.5}}}
\@writefile{brf}{\backcite{chen2018cartoongan}{{3}{2.5}{subsection.2.5}}}
\@writefile{brf}{\backcite{li2019im2pencil}{{3}{2.5}{subsection.2.5}}}
\@writefile{brf}{\backcite{zhang2016colorful}{{3}{2.5}{subsection.2.5}}}
\@writefile{brf}{\backcite{zhang2018two}{{3}{2.5}{subsection.2.5}}}
\@writefile{brf}{\backcite{CycleGAN2017}{{3}{2.5}{subsection.2.5}}}
\@writefile{toc}{\contentsline {section}{\numberline {3}\hskip -1em.~Proposed Approach}{3}{section.3}\protected@file@percent }
\@writefile{brf}{\backcite{simonyan2014very}{{3}{3}{section.3}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}\hskip -1em.~Learning From the Surface Representation}{3}{subsection.3.1}\protected@file@percent }
\citation{uijlings2013selective}
\citation{simonyan2014very}
\newlabel{eqn:equation1}{{1}{4}{\hskip -1em.~Learning From the Surface Representation}{equation.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}\hskip -1em.~Learning From the Structure representation}{4}{subsection.3.2}\protected@file@percent }
\@writefile{brf}{\backcite{uijlings2013selective}{{4}{3.2}{subsection.3.2}}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Segmentation for the Structure Representation}}{4}{algorithm.1}\protected@file@percent }
\newlabel{alg:algorithmic1}{{1}{4}{\hskip -1em.~Learning From the Structure representation}{algorithm.1}{}}
\newlabel{eqn:equation2}{{2}{4}{\hskip -1em.~Learning From the Structure representation}{equation.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Adaptive coloring algorithm. (a) shows average colored segmentation map and (c) shows adaptively colored segmentation map, which are brighter and have higher contrast.}}{4}{figure.4}\protected@file@percent }
\newlabel{fig:color_algorithm}{{4}{4}{Adaptive coloring algorithm. (a) shows average colored segmentation map and (c) shows adaptively colored segmentation map, which are brighter and have higher contrast}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Removal of hazing effect. (a) shows results trained with average colored structure representations, which suffer from hazing effects. (b) shows results trained with adaptively colored structure representations, which are brighter and free from hazing effects.}}{4}{figure.5}\protected@file@percent }
\newlabel{fig:hazing}{{5}{4}{Removal of hazing effect. (a) shows results trained with average colored structure representations, which suffer from hazing effects. (b) shows results trained with adaptively colored structure representations, which are brighter and free from hazing effects}{figure.5}{}}
\@writefile{brf}{\backcite{simonyan2014very}{{4}{3.2}{equation.3.2}}}
\newlabel{eqn:equation3}{{3}{4}{\hskip -1em.~Learning From the Structure representation}{equation.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}\hskip -1em.~Learning From the Textural Representation}{4}{subsection.3.3}\protected@file@percent }
\newlabel{eqn:equation4}{{4}{4}{\hskip -1em.~Learning From the Textural Representation}{equation.3.4}{}}
\newlabel{eqn:equation5}{{5}{4}{\hskip -1em.~Learning From the Textural Representation}{equation.3.5}{}}
\citation{aly2005image}
\citation{abadi2016tensorflow}
\citation{isola2017image}
\citation{kingma2014adam}
\citation{karras2019style}
\citation{CycleGAN2017}
\citation{lin2014microsoft}
\citation{johnson2016perceptual}
\citation{CycleGAN2017}
\citation{chen2018cartoongan}
\citation{heusel2017gans}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}\hskip -1em.~Full model}{5}{subsection.3.4}\protected@file@percent }
\newlabel{eqn:equation6}{{6}{5}{\hskip -1em.~Full model}{equation.3.6}{}}
\@writefile{brf}{\backcite{aly2005image}{{5}{3.4}{equation.3.6}}}
\newlabel{eqn:equation7}{{7}{5}{\hskip -1em.~Full model}{equation.3.7}{}}
\newlabel{eqn:equation8}{{8}{5}{\hskip -1em.~Full model}{equation.3.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}\hskip -1em.~Post processing and Style Interpolation}{5}{subsection.3.5}\protected@file@percent }
\newlabel{eqn:equation9}{{9}{5}{\hskip -1em.~Post processing and Style Interpolation}{equation.3.9}{}}
\newlabel{eqn:equation10}{{10}{5}{\hskip -1em.~Post processing and Style Interpolation}{equation.3.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}\hskip -1em.~Experimental Results}{5}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}\hskip -1em.~Experimental Setup}{5}{subsection.4.1}\protected@file@percent }
\@writefile{brf}{\backcite{abadi2016tensorflow}{{5}{4.1}{subsection.4.1}}}
\@writefile{brf}{\backcite{isola2017image}{{5}{4.1}{subsection.4.1}}}
\@writefile{brf}{\backcite{kingma2014adam}{{5}{4.1}{subsection.4.1}}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Illustration of post-processing. (a) Our post processing can effectively turn noisy images(left) to clean images(right). (b) The sharpness of details could be adjusted. $\delta $ = 0.0, 0.25, 0.5, 0.75, 1.0 from left to right. Zoom in for details.}}{5}{figure.6}\protected@file@percent }
\newlabel{fig:post_processing}{{6}{5}{Illustration of post-processing. (a) Our post processing can effectively turn noisy images(left) to clean images(right). (b) The sharpness of details could be adjusted. $\delta $ = 0.0, 0.25, 0.5, 0.75, 1.0 from left to right. Zoom in for details}{figure.6}{}}
\@writefile{brf}{\backcite{karras2019style}{{5}{4.1}{subsection.4.1}}}
\@writefile{brf}{\backcite{CycleGAN2017}{{5}{4.1}{subsection.4.1}}}
\@writefile{brf}{\backcite{lin2014microsoft}{{5}{4.1}{subsection.4.1}}}
\@writefile{brf}{\backcite{johnson2016perceptual}{{5}{4.1}{subsection.4.1}}}
\@writefile{brf}{\backcite{CycleGAN2017}{{5}{4.1}{subsection.4.1}}}
\@writefile{brf}{\backcite{chen2018cartoongan}{{5}{4.1}{subsection.4.1}}}
\citation{chen2018cartoongan}
\citation{chen2018cartoongan}
\citation{johnson2016perceptual}
\citation{chen2018cartoongan}
\citation{CycleGAN2017}
\citation{johnson2016perceptual}
\citation{CycleGAN2017}
\citation{chen2018cartoongan}
\citation{chen2018cartoongan}
\citation{chen2018cartoongan}
\citation{chen2018cartoongan}
\citation{chen2018cartoongan}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Results of our method in different scenes. Zoom in for details}}{6}{figure.7}\protected@file@percent }
\newlabel{fig:diverse_scenes}{{7}{6}{Results of our method in different scenes. Zoom in for details}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Output quality could be controlled by adjusting weight of each representation. Zoom in for details.}}{6}{figure.8}\protected@file@percent }
\newlabel{fig:figure5}{{8}{6}{Output quality could be controlled by adjusting weight of each representation. Zoom in for details}{figure.8}{}}
\@writefile{brf}{\backcite{johnson2016perceptual}{{6}{4.1}{figure.9}}}
\@writefile{brf}{\backcite{chen2018cartoongan}{{6}{4.1}{figure.9}}}
\@writefile{brf}{\backcite{CycleGAN2017}{{6}{4.1}{figure.9}}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Performance and model size comparison, LR represents 256*256 resolution, while HR represents 720*1280 resolution}}{6}{table.1}\protected@file@percent }
\newlabel{table:speed}{{1}{6}{Performance and model size comparison, LR represents 256*256 resolution, while HR represents 720*1280 resolution}{table.1}{}}
\@writefile{brf}{\backcite{heusel2017gans}{{6}{4.1}{subsection.4.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}\hskip -1em.~Validation of Cartoon Representations.}{6}{subsection.4.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Classification accuracy and FID evaluation of our proposed cartoon representation.}}{6}{table.2}\protected@file@percent }
\newlabel{table:prior}{{2}{6}{Classification accuracy and FID evaluation of our proposed cartoon representation}{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}\hskip -1em.~Illustration of Controllability}{6}{subsection.4.3}\protected@file@percent }
\citation{heusel2017gans}
\citation{szegedy2016rethinking}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Qualitative comparison of our method and previous methods. The Hosoda style, Shinkai style, Hayao style and Paprika style of CartoonGAN \cite  {chen2018cartoongan} are shown in row 1-4 respectively. Zoom in for details}}{7}{figure.9}\protected@file@percent }
\@writefile{brf}{\backcite{chen2018cartoongan}{{7}{9}{figure.9}}}
\newlabel{fig:comparison}{{9}{7}{Qualitative comparison of our method and previous methods. The Hosoda style, Shinkai style, Hayao style and Paprika style of CartoonGAN \cite {chen2018cartoongan} are shown in row 1-4 respectively. Zoom in for details}{figure.9}{}}
\@writefile{brf}{\backcite{johnson2016perceptual}{{7}{4.2}{table.2}}}
\@writefile{brf}{\backcite{CycleGAN2017}{{7}{4.2}{table.2}}}
\@writefile{brf}{\backcite{chen2018cartoongan}{{7}{4.2}{table.2}}}
\@writefile{brf}{\backcite{chen2018cartoongan}{{7}{4.2}{table.2}}}
\@writefile{brf}{\backcite{chen2018cartoongan}{{7}{4.2}{table.2}}}
\@writefile{brf}{\backcite{chen2018cartoongan}{{7}{4.2}{table.2}}}
\@writefile{brf}{\backcite{chen2018cartoongan}{{7}{4.2}{table.2}}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Performance evaluation based on FID}}{7}{table.3}\protected@file@percent }
\newlabel{table:table1}{{3}{7}{Performance evaluation based on FID}{table.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}\hskip -1em.~Qualitative Comparison}{7}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}\hskip -1em.~Quantitative Evaluation}{7}{subsection.4.5}\protected@file@percent }
\@writefile{brf}{\backcite{heusel2017gans}{{7}{4.5}{subsection.4.5}}}
\@writefile{brf}{\backcite{szegedy2016rethinking}{{7}{4.5}{subsection.4.5}}}
\citation{johnson2016perceptual}
\citation{chen2018cartoongan}
\citation{CycleGAN2017}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Ablation study by removing each component}}{8}{figure.10}\protected@file@percent }
\newlabel{fig:figure7}{{10}{8}{Ablation study by removing each component}{figure.10}{}}
\@writefile{brf}{\backcite{johnson2016perceptual}{{8}{4.6}{subsection.4.6}}}
\@writefile{brf}{\backcite{chen2018cartoongan}{{8}{4.6}{subsection.4.6}}}
\@writefile{brf}{\backcite{CycleGAN2017}{{8}{4.6}{subsection.4.6}}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Result of User study, higher score means better quality. Row 1 and 2 represent the mean and standard error of Cartoon quality score, row 3 and 4 represent the mean and standard error of Overall quality score.}}{8}{table.4}\protected@file@percent }
\newlabel{table:user_study}{{4}{8}{Result of User study, higher score means better quality. Row 1 and 2 represent the mean and standard error of Cartoon quality score, row 3 and 4 represent the mean and standard error of Overall quality score}{table.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}\hskip -1em.~User Study}{8}{subsection.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}\hskip -1em.~Analysis of Each Components}{8}{subsection.4.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}\hskip -1em.~Conclusion}{8}{section.5}\protected@file@percent }
\bibstyle{ieee_fullname}
\bibdata{egbib}
\bibcite{abadi2016tensorflow}{1}
\bibcite{achanta2012slic}{2}
\bibcite{aly2005image}{3}
\bibcite{bi20151}{4}
\bibcite{chen2018cartoongan}{5}
\bibcite{comaniciu2002mean}{6}
\bibcite{curtis1997computer}{7}
\bibcite{dumoulin2016learned}{8}
\bibcite{fan2017generic}{9}
\bibcite{fan2018image}{10}
\bibcite{farbman2008edge}{11}
\bibcite{felzenszwalb2004efficient}{12}
\bibcite{gatys2015neural}{13}
\bibcite{goodfellow2014generative}{14}
\bibcite{he2010guided}{15}
\bibcite{heusel2017gans}{16}
\bibcite{huang2017arbitrary}{17}
\bibcite{huang2018multimodal}{18}
\bibcite{ignatov2018wespe}{19}
\bibcite{isola2017image}{20}
\bibcite{johnson2016perceptual}{21}
\bibcite{karras2019style}{22}
\bibcite{kingma2014adam}{23}
\bibcite{lee2018diverse}{24}
\bibcite{levinshtein2009turbopixels}{25}
\bibcite{li2019im2pencil}{26}
\bibcite{li2017universal}{27}
\bibcite{lin2014microsoft}{28}
\bibcite{lu2012combining}{29}
\bibcite{min2014fast}{30}
\bibcite{moore2008superpixel}{31}
\bibcite{mori2005guiding}{32}
\bibcite{pathak2016context}{33}
\bibcite{rosin2015non}{34}
\bibcite{sanakoyeu2018style}{35}
\bibcite{shahcheraghi2013effects}{36}
\bibcite{simonyan2014very}{37}
\bibcite{szegedy2016rethinking}{38}
\bibcite{tomasi1998bilateral}{39}
\bibcite{uijlings2013selective}{40}
\bibcite{van2004real}{41}
\bibcite{vedaldi2008quick}{42}
\bibcite{wang2004video}{43}
\bibcite{wu2018fast}{44}
\bibcite{xu2011image}{45}
\bibcite{xu2015deep}{46}
\bibcite{yang2010semantics}{47}
\bibcite{zhang2018two}{48}
\bibcite{zhang2016colorful}{49}
\bibcite{CycleGAN2017}{50}
